{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:39.310188Z",
     "start_time": "2024-09-14T10:43:39.237189Z"
    }
   },
   "source": [
    "from GRASP import GRASP"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:39.643754Z",
     "start_time": "2024-09-14T10:43:39.328189Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:39.993354Z",
     "start_time": "2024-09-14T10:43:39.946354Z"
    }
   },
   "source": [
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def compute_overlap_area(polygons):\n",
    "    \"\"\"\n",
    "    Compute the overlap area between multiple polygons.\n",
    "    \"\"\"\n",
    "    if len(polygons) < 4:\n",
    "        return 0\n",
    "\n",
    "    # Create Shapely Polygon objects\n",
    "    shapely_polygons = []\n",
    "    for polygon in polygons:\n",
    "        poly = Polygon(polygon)\n",
    "        if not poly.is_valid:\n",
    "            poly = poly.buffer(0)  # Attempt to fix the invalid polygon\n",
    "        shapely_polygons.append(poly)\n",
    "\n",
    "    # Compute the union of all polygons\n",
    "    union_polygon = unary_union(shapely_polygons)\n",
    "\n",
    "    # Compute individual areas\n",
    "    individual_areas = [polygon.area for polygon in shapely_polygons]\n",
    "    total_individual_area = sum(individual_areas)\n",
    "\n",
    "    # Compute union area\n",
    "    union_area = union_polygon.area\n",
    "\n",
    "    # Compute overlap area\n",
    "    overlap_area = total_individual_area - union_area\n",
    "\n",
    "    return overlap_area"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:40.057354Z",
     "start_time": "2024-09-14T10:43:40.042354Z"
    }
   },
   "source": [
    "def compute_turning_degree(lat_lon_sequence, num_directions=8):\n",
    "    \"\"\"\n",
    "    Compute the turning degree of a sequence of latitude and longitude points,\n",
    "    and calculate the repeated distance due to turns.\n",
    "    \"\"\"\n",
    "    # Define directions in radians\n",
    "    directions = np.linspace(0, 2 * np.pi, num_directions, endpoint=False)\n",
    "    \n",
    "    # Compute differences between consecutive points\n",
    "    deltas = np.diff(lat_lon_sequence, axis=0)\n",
    "    distances = np.linalg.norm(deltas, axis=1)\n",
    "    angles = np.arctan2(deltas[:, 1], deltas[:, 0])\n",
    "    \n",
    "    # Project the angles to the defined directions\n",
    "    projection_indices = np.digitize(angles, directions) % num_directions\n",
    "    \n",
    "    # Count turning points\n",
    "    turning_points = np.sum(np.abs(np.diff(projection_indices)) > 0)\n",
    "    \n",
    "    # Compute total path distance\n",
    "    total_distance = np.sum(distances)\n",
    "    \n",
    "    # Compute repeated distance\n",
    "    direction_distances = np.zeros(num_directions)\n",
    "    repeated_distance = 0\n",
    "    \n",
    "    for i in range(len(projection_indices)):\n",
    "        direction = projection_indices[i]\n",
    "        opposite_direction = (direction + num_directions // 2) % num_directions\n",
    "        if direction_distances[opposite_direction] > 0:\n",
    "            repeated_distance += min(distances[i], direction_distances[opposite_direction])\n",
    "            direction_distances[opposite_direction] -= min(distances[i], direction_distances[opposite_direction])\n",
    "        direction_distances[direction] += distances[i]\n",
    "    \n",
    "    return turning_points, total_distance, repeated_distance"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:40.087355Z",
     "start_time": "2024-09-14T10:43:40.071354Z"
    }
   },
   "source": [
    "def compute_average_turning_angle(lat_lon_sequence):\n",
    "    \"\"\"\n",
    "    Compute the average turning angle of a path.\n",
    "    If the input is insufficient or there's any issue, returns 0.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(lat_lon_sequence) < 3:  # 确保有足够的点来计算两次差分\n",
    "            return 0  # 不足三个点时返回0\n",
    "\n",
    "        deltas = np.diff(lat_lon_sequence, axis=0)\n",
    "        if np.any(np.all(deltas == 0, axis=1)):  # 检查是否有连续重复的点\n",
    "            return 0  # 存在连续重复点时返回0\n",
    "\n",
    "        angles = np.arctan2(deltas[:, 1], deltas[:, 0])\n",
    "        angle_changes = np.diff(angles)\n",
    "        angle_changes = (angle_changes + np.pi) % (2 * np.pi) - np.pi\n",
    "        average_turning_angle = np.mean(np.abs(angle_changes))\n",
    "        return average_turning_angle\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")  # 打印错误信息\n",
    "        return 0  # 遇到任何异常时返回0\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:40.118354Z",
     "start_time": "2024-09-14T10:43:40.104355Z"
    }
   },
   "source": [
    "def compute_path_smoothness(lat_lon_sequence):\n",
    "    \"\"\"\n",
    "    Compute the smoothness of a path using curvature.\n",
    "    \"\"\"\n",
    "    deltas = np.diff(lat_lon_sequence, axis=0)\n",
    "    angles = np.arctan2(deltas[:, 1], deltas[:, 0])\n",
    "    angle_changes = np.diff(angles)\n",
    "    angle_changes = (angle_changes + np.pi) % (2 * np.pi) - np.pi\n",
    "    curvature = np.sum(np.abs(angle_changes))\n",
    "    return curvature"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:40.150354Z",
     "start_time": "2024-09-14T10:43:40.135355Z"
    }
   },
   "source": [
    "def plot_route(lat_lon_sequence, title=\"Route Plot\", plts=None, plt_a=None):\n",
    "    \"\"\"\n",
    "    Plot the route given a sequence of latitude and longitude points.\n",
    "    \"\"\"\n",
    "    lat_lon_sequence = np.array(lat_lon_sequence)\n",
    "    latitudes = lat_lon_sequence[:, 0]\n",
    "    longitudes = lat_lon_sequence[:, 1]\n",
    "    \n",
    "    if plts is None:\n",
    "        pltt = plt\n",
    "        pltt.figure(figsize=(5, 3))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(plts[0], plts[1])\n",
    "        fig.suptitle(title)\n",
    "        if plts[0] == 1:\n",
    "            pltt = axs[plt_a[1]]\n",
    "        else:\n",
    "            pltt = axs[plt_a[0], plt_a[1]]\n",
    "    pltt.plot(longitudes, latitudes, marker='o', color='b', label='Route')\n",
    "    pltt.scatter(longitudes[0], latitudes[0], color='g', s=200, label='Start')\n",
    "    pltt.scatter(longitudes[-1], latitudes[-1], color='r', s=100, label='End')\n",
    "    \n",
    "    for i, (lon, lat) in enumerate(zip(longitudes, latitudes)):\n",
    "        pltt.text(lon, lat, f'{i}', fontsize=12, ha='right')\n",
    "    \n",
    "    pltt.title(title)\n",
    "    pltt.xlabel('Longitude')\n",
    "    pltt.ylabel('Latitude')\n",
    "    pltt.legend()\n",
    "    pltt.grid(True)\n",
    "    pltt.show()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:40.469354Z",
     "start_time": "2024-09-14T10:43:40.167354Z"
    }
   },
   "source": [
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "def compute_frechet_distance(route1, route2):\n",
    "    \"\"\"\n",
    "    Compute the Fréchet distance between two routes.\n",
    "    \"\"\"\n",
    "    route1 = np.array(route1)\n",
    "    route2 = np.array(route2)\n",
    "    \n",
    "    u = np.vstack((route1, route2))\n",
    "    frechet_dist = max(directed_hausdorff(route1, route2)[0], directed_hausdorff(route2, route1)[0])\n",
    "    return frechet_dist"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:40.517354Z",
     "start_time": "2024-09-14T10:43:40.488355Z"
    }
   },
   "source": [
    "import dataset_config as dataset_config\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "dataConfig = dataset_config.DatasetConfig()\n",
    "\n",
    "database = dataConfig.database\n",
    "poi_dict = dataConfig.poi_dict\n",
    "database_function = dataConfig.database_func\n",
    "poi_cate_dict = dataConfig.poi_cate_dict\n",
    "\n",
    "def safe_get(dictionary, key, expected_type, default):\n",
    "    value = dictionary.get(key, default)\n",
    "    return value if isinstance(value, expected_type) else default\n",
    "\n",
    "def run_experiment_cases(case_datasets, exp_replace=True, use_cluster=True):\n",
    "    # 运行每个实例并收集结果\n",
    "    results_list = []\n",
    "    ts_list = []\n",
    "    database.connect()\n",
    "    for row in tqdm(case_datasets):\n",
    "        # if len(row['poi_name_list']) == 0:\n",
    "        #     continue\n",
    "        default_N_c_min = [0, 2, 2]\n",
    "        default_N_c_max = [10, 3, 2]\n",
    "        default_route_num = 3\n",
    "        default_use_min_restaurant_gap = 3\n",
    "        default_start_day_time = \"09:00:00\"\n",
    "        default_plan_max_time = 12\n",
    "        default_tightness_w = 1.0\n",
    "\n",
    "        # Update database retrieval and type checking\n",
    "        poi_list = database_function['getIdbyName'](row.get('poi_id_list', []), poi_cate_dict['attraction'])\n",
    "        poi_id_list = [i[0] for i in poi_list]\n",
    "        poi_id_list = list(set(poi_id_list))\n",
    "\n",
    "        # Initialize GRASP with safe_get\n",
    "        plan_entity = GRASP(\n",
    "            N_c_min=[0, safe_get(row, 'N_c_min', list, default_N_c_min)[1], 2],\n",
    "            N_c_max=[100, safe_get(row, 'N_c_max', list, default_N_c_max)[1], 2],\n",
    "            maxIterations=1, \n",
    "            poi_id_list=poi_id_list, \n",
    "            route_num=safe_get(row, 'route_num', int, default_route_num),\n",
    "            not_poi_list=[],\n",
    "            use_min_restaurant_gap=safe_get(row, 'use_min_restaurant_gap', int, default_use_min_restaurant_gap) * 3600 if safe_get(row, 'use_min_restaurant_gap', int, default_use_min_restaurant_gap) < 3600 else safe_get(row, 'use_min_restaurant_gap', int, default_use_min_restaurant_gap),\n",
    "            start_day_time=safe_get(row, 'start_day_time', str, default_start_day_time),\n",
    "            plan_max_time=safe_get(row, 'plan_max_time', int, default_plan_max_time) if safe_get(row, 'plan_max_time', int, default_plan_max_time) >= 10 else 10,\n",
    "            tightness_w=safe_get(row, 'tightness_w', float, default_tightness_w),\n",
    "            exp_replace=exp_replace,\n",
    "            use_cluster=use_cluster\n",
    "        )\n",
    "        \n",
    "        results, st, wt, ts, tt, ds = plan_entity.GRASP()\n",
    "        results_list.append(results)\n",
    "        ts_list.append(ts)\n",
    "\n",
    "    # 计算每个实例的指标\n",
    "    metrics = []\n",
    "    ts_raw = 0\n",
    "    for results in results_list:\n",
    "        results_geos = []\n",
    "        for result in results:\n",
    "            results_geos.append([(poi[poi_dict['poi_long']], poi[poi_dict['poi_lat']]) for poi in result])\n",
    "        # print(results_geos)\n",
    "        # results_geos = np.asarray(results_geos)\n",
    "\n",
    "        instance_metrics = []\n",
    "        overlap_area = max(0, compute_overlap_area(results_geos))\n",
    "        for i, result in enumerate(results_geos):\n",
    "            turning_points, total_distance, repeated_distance = compute_turning_degree(result)\n",
    "            average_turning_angle = compute_average_turning_angle(result)\n",
    "            smoothness = compute_path_smoothness(result)\n",
    "            frechet_distance = 0\n",
    "            if len(results_geos) > 1:\n",
    "                for j in range(len(results_geos)):\n",
    "                    if i != j:\n",
    "                        frechet_distance += compute_frechet_distance(result, results_geos[j])\n",
    "                frechet_distance /= (len(results_geos) - 1)\n",
    "            instance_metrics.append({\n",
    "                \"turning_points\": turning_points,\n",
    "                \"total_distance\": total_distance,\n",
    "                \"repeated_distance\": repeated_distance,\n",
    "                \"average_turning_angle\": average_turning_angle,\n",
    "                \"smoothness\": smoothness,\n",
    "                \"overlap_area\": overlap_area,\n",
    "                \"frechet_distance\": frechet_distance\n",
    "            })\n",
    "        metrics.append(instance_metrics)\n",
    "        \n",
    "        for result in results:\n",
    "            # results_score.append([poi[poi_dict['poi_score']] * math.log2(poi[poi_dict['poi_comment_num']] + 1) for poi in result])\n",
    "            ts_raw += sum([poi[poi_dict['poi_score']] * math.log2(poi[poi_dict['poi_comment_num']] + 1) for poi in result])\n",
    "\n",
    "    # 计算平均值\n",
    "    average_metrics = {\n",
    "        \"turning_points\": 0,\n",
    "        \"total_distance\": 0,\n",
    "        \"repeated_distance\": 0,\n",
    "        \"average_turning_angle\": 0,\n",
    "        \"smoothness\": 0,\n",
    "        \"overlap_area\": 0,\n",
    "        \"frechet_distance\": 0,\n",
    "        \"ts\": 0,\n",
    "        \"ts_raw\": ts_raw\n",
    "    }\n",
    "\n",
    "    num_routes = len(metrics) * len(metrics[0])\n",
    "    for instance_metrics in metrics:\n",
    "        for route_metrics in instance_metrics:\n",
    "            average_metrics[\"turning_points\"] += route_metrics[\"turning_points\"]\n",
    "            average_metrics[\"total_distance\"] += route_metrics[\"total_distance\"]\n",
    "            average_metrics[\"repeated_distance\"] += route_metrics[\"repeated_distance\"]\n",
    "            average_metrics[\"average_turning_angle\"] += route_metrics[\"average_turning_angle\"]\n",
    "            average_metrics[\"smoothness\"] += route_metrics[\"smoothness\"]\n",
    "            average_metrics[\"overlap_area\"] += route_metrics[\"overlap_area\"]\n",
    "            average_metrics[\"frechet_distance\"] += route_metrics[\"frechet_distance\"]\n",
    "    for ts in ts_list:\n",
    "        for s in ts:\n",
    "            average_metrics[\"ts\"] += s\n",
    "\n",
    "    for key in average_metrics:\n",
    "        average_metrics[key] /= num_routes\n",
    "        \n",
    "    database.close()\n",
    "\n",
    "    return average_metrics"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:40.548354Z",
     "start_time": "2024-09-14T10:43:40.533355Z"
    }
   },
   "source": [
    "# 取消输出warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:43:48.089522Z",
     "start_time": "2024-09-14T10:43:40.566355Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "with open(\"final_datas/6-final_data_glm4air_wo_classifier.json\",'r', encoding='UTF-8') as f:\n",
    "     cases_dataset = json.load(f)\n",
    "\n",
    "#取前10个case进行测试\n",
    "cases_dataset = cases_dataset[:10]\n",
    "\n",
    "avg_metrics = run_experiment_cases(cases_dataset, use_cluster=False)\n",
    "print(\"Average metrics:\")\n",
    "print(f\"Turning points: {avg_metrics['turning_points']:.2f}\")\n",
    "print(f\"Total distance: {avg_metrics['total_distance']:.2f}\")\n",
    "print(f\"repeated_distance: {avg_metrics['repeated_distance']:.4f}\")\n",
    "print(f\"Average turning angle: {avg_metrics['average_turning_angle']:.2f}\")\n",
    "print(f\"Smoothness: {avg_metrics['smoothness']:.2f}\")\n",
    "print(f\"Overlap area: {avg_metrics['overlap_area']}\")\n",
    "print(f\"Fréchet distance: {avg_metrics['frechet_distance']:.2f}\")\n",
    "print(f\"Total score: {avg_metrics['ts']}\")\n",
    "print(f\"Total score raw: {avg_metrics['ts_raw']}\")\n",
    "print(\"\\n\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:\n",
      "Turning points: 3.42\n",
      "Total distance: 0.96\n",
      "repeated_distance: 0.1459\n",
      "Average turning angle: 2.12\n",
      "Smoothness: 8.90\n",
      "Overlap area: 0.019453081345859317\n",
      "Fréchet distance: 0.28\n",
      "Total score: 97.99141875004176\n",
      "Total score raw: 178.40059101997514\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T11:22:33.536050Z",
     "start_time": "2024-09-14T10:43:48.260523Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "with open(\"final_datas/6-final_data_glm4air_wo_classifier.json\",'r', encoding='UTF-8') as f:\n",
    "     cases_dataset = json.load(f)\n",
    "\n",
    "avg_metrics = run_experiment_cases(cases_dataset)\n",
    "print(\"Average metrics:\")\n",
    "print(f\"Turning points: {avg_metrics['turning_points']:.2f}\")\n",
    "print(f\"Total distance: {avg_metrics['total_distance']:.2f}\")\n",
    "print(f\"repeated_distance: {avg_metrics['repeated_distance']:.4f}\")\n",
    "print(f\"Average turning angle: {avg_metrics['average_turning_angle']:.2f}\")\n",
    "print(f\"Smoothness: {avg_metrics['smoothness']:.2f}\")\n",
    "print(f\"Overlap area: {avg_metrics['overlap_area']}\")\n",
    "print(f\"Fréchet distance: {avg_metrics['frechet_distance']:.2f}\")\n",
    "print(f\"Total score: {avg_metrics['ts']}\")\n",
    "print(f\"Total score raw: {avg_metrics['ts_raw']}\")\n",
    "print(\"\\n\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2640/2640 [38:37<00:00,  1.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:\n",
      "Turning points: 2.55\n",
      "Total distance: 0.12\n",
      "repeated_distance: 0.0221\n",
      "Average turning angle: 0.94\n",
      "Smoothness: 6.26\n",
      "Overlap area: 0.0004696847104794534\n",
      "Fréchet distance: 0.03\n",
      "Total score: 96.78583621072235\n",
      "Total score raw: 155.58443528970957\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
