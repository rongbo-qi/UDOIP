{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:01.702257800Z",
     "start_time": "2024-08-16T05:04:01.403411Z"
    }
   },
   "outputs": [],
   "source": [
    "from GRASP import GRASP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:02.602493800Z",
     "start_time": "2024-08-16T05:04:01.703257400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:02.820005400Z",
     "start_time": "2024-08-16T05:04:02.602493800Z"
    }
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def compute_overlap_area(polygons):\n",
    "    \"\"\"\n",
    "    Compute the overlap area between multiple polygons.\n",
    "    \"\"\"\n",
    "    if len(polygons) < 4:\n",
    "        return 0\n",
    "\n",
    "    # Create Shapely Polygon objects\n",
    "    shapely_polygons = []\n",
    "    for polygon in polygons:\n",
    "        poly = Polygon(polygon)\n",
    "        if not poly.is_valid:\n",
    "            poly = poly.buffer(0)  # Attempt to fix the invalid polygon\n",
    "        shapely_polygons.append(poly)\n",
    "\n",
    "    # Compute the union of all polygons\n",
    "    union_polygon = unary_union(shapely_polygons)\n",
    "\n",
    "    # Compute individual areas\n",
    "    individual_areas = [polygon.area for polygon in shapely_polygons]\n",
    "    total_individual_area = sum(individual_areas)\n",
    "\n",
    "    # Compute union area\n",
    "    union_area = union_polygon.area\n",
    "\n",
    "    # Compute overlap area\n",
    "    overlap_area = total_individual_area - union_area\n",
    "\n",
    "    return overlap_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:02.840255100Z",
     "start_time": "2024-08-16T05:04:02.823009400Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_turning_degree(lat_lon_sequence, num_directions=8):\n",
    "    \"\"\"\n",
    "    Compute the turning degree of a sequence of latitude and longitude points,\n",
    "    and calculate the repeated distance due to turns.\n",
    "    \"\"\"\n",
    "    # Define directions in radians\n",
    "    directions = np.linspace(0, 2 * np.pi, num_directions, endpoint=False)\n",
    "    \n",
    "    # Compute differences between consecutive points\n",
    "    deltas = np.diff(lat_lon_sequence, axis=0)\n",
    "    distances = np.linalg.norm(deltas, axis=1)\n",
    "    angles = np.arctan2(deltas[:, 1], deltas[:, 0])\n",
    "    \n",
    "    # Project the angles to the defined directions\n",
    "    projection_indices = np.digitize(angles, directions) % num_directions\n",
    "    \n",
    "    # Count turning points\n",
    "    turning_points = np.sum(np.abs(np.diff(projection_indices)) > 0)\n",
    "    \n",
    "    # Compute total path distance\n",
    "    total_distance = np.sum(distances)\n",
    "    \n",
    "    # Compute repeated distance\n",
    "    direction_distances = np.zeros(num_directions)\n",
    "    repeated_distance = 0\n",
    "    \n",
    "    for i in range(len(projection_indices)):\n",
    "        direction = projection_indices[i]\n",
    "        opposite_direction = (direction + num_directions // 2) % num_directions\n",
    "        if direction_distances[opposite_direction] > 0:\n",
    "            repeated_distance += min(distances[i], direction_distances[opposite_direction])\n",
    "            direction_distances[opposite_direction] -= min(distances[i], direction_distances[opposite_direction])\n",
    "        direction_distances[direction] += distances[i]\n",
    "    \n",
    "    return turning_points, total_distance, repeated_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:02.852256200Z",
     "start_time": "2024-08-16T05:04:02.839255900Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_average_turning_angle(lat_lon_sequence):\n",
    "    \"\"\"\n",
    "    Compute the average turning angle of a path.\n",
    "    If the input is insufficient or there's any issue, returns 0.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(lat_lon_sequence) < 3:  # 确保有足够的点来计算两次差分\n",
    "            return 0  # 不足三个点时返回0\n",
    "\n",
    "        deltas = np.diff(lat_lon_sequence, axis=0)\n",
    "        if np.any(np.all(deltas == 0, axis=1)):  # 检查是否有连续重复的点\n",
    "            return 0  # 存在连续重复点时返回0\n",
    "\n",
    "        angles = np.arctan2(deltas[:, 1], deltas[:, 0])\n",
    "        angle_changes = np.diff(angles)\n",
    "        angle_changes = (angle_changes + np.pi) % (2 * np.pi) - np.pi\n",
    "        average_turning_angle = np.mean(np.abs(angle_changes))\n",
    "        return average_turning_angle\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")  # 打印错误信息\n",
    "        return 0  # 遇到任何异常时返回0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:02.868258900Z",
     "start_time": "2024-08-16T05:04:02.853258700Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_path_smoothness(lat_lon_sequence):\n",
    "    \"\"\"\n",
    "    Compute the smoothness of a path using curvature.\n",
    "    \"\"\"\n",
    "    deltas = np.diff(lat_lon_sequence, axis=0)\n",
    "    angles = np.arctan2(deltas[:, 1], deltas[:, 0])\n",
    "    angle_changes = np.diff(angles)\n",
    "    angle_changes = (angle_changes + np.pi) % (2 * np.pi) - np.pi\n",
    "    curvature = np.sum(np.abs(angle_changes))\n",
    "    return curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:02.888257800Z",
     "start_time": "2024-08-16T05:04:02.870256500Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_route(lat_lon_sequence, title=\"Route Plot\", plts=None, plt_a=None):\n",
    "    \"\"\"\n",
    "    Plot the route given a sequence of latitude and longitude points.\n",
    "    \"\"\"\n",
    "    lat_lon_sequence = np.array(lat_lon_sequence)\n",
    "    latitudes = lat_lon_sequence[:, 0]\n",
    "    longitudes = lat_lon_sequence[:, 1]\n",
    "    \n",
    "    if plts is None:\n",
    "        pltt = plt\n",
    "        pltt.figure(figsize=(5, 3))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(plts[0], plts[1])\n",
    "        fig.suptitle(title)\n",
    "        if plts[0] == 1:\n",
    "            pltt = axs[plt_a[1]]\n",
    "        else:\n",
    "            pltt = axs[plt_a[0], plt_a[1]]\n",
    "    pltt.plot(longitudes, latitudes, marker='o', color='b', label='Route')\n",
    "    pltt.scatter(longitudes[0], latitudes[0], color='g', s=200, label='Start')\n",
    "    pltt.scatter(longitudes[-1], latitudes[-1], color='r', s=100, label='End')\n",
    "    \n",
    "    for i, (lon, lat) in enumerate(zip(longitudes, latitudes)):\n",
    "        pltt.text(lon, lat, f'{i}', fontsize=12, ha='right')\n",
    "    \n",
    "    pltt.title(title)\n",
    "    pltt.xlabel('Longitude')\n",
    "    pltt.ylabel('Latitude')\n",
    "    pltt.legend()\n",
    "    pltt.grid(True)\n",
    "    pltt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:03.792343400Z",
     "start_time": "2024-08-16T05:04:02.886256200Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "def compute_frechet_distance(route1, route2):\n",
    "    \"\"\"\n",
    "    Compute the Fréchet distance between two routes.\n",
    "    \"\"\"\n",
    "    route1 = np.array(route1)\n",
    "    route2 = np.array(route2)\n",
    "    \n",
    "    u = np.vstack((route1, route2))\n",
    "    frechet_dist = max(directed_hausdorff(route1, route2)[0], directed_hausdorff(route2, route1)[0])\n",
    "    return frechet_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:03.903456800Z",
     "start_time": "2024-08-16T05:04:03.798345800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dataset_config as dataset_config\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "dataConfig = dataset_config.DatasetConfig()\n",
    "\n",
    "database = dataConfig.database\n",
    "poi_dict = dataConfig.poi_dict\n",
    "database_function = dataConfig.database_func\n",
    "poi_cate_dict = dataConfig.poi_cate_dict\n",
    "\n",
    "def safe_get(dictionary, key, expected_type, default):\n",
    "    value = dictionary.get(key, default)\n",
    "    return value if isinstance(value, expected_type) else default\n",
    "\n",
    "def run_experiment_cases(case_datasets, exp_replace=True, use_cluster=True):\n",
    "    # 运行每个实例并收集结果\n",
    "    results_list = []\n",
    "    ts_list = []\n",
    "    database.connect()\n",
    "    for row in tqdm(case_datasets):\n",
    "        # if len(row['poi_name_list']) == 0:\n",
    "        #     continue\n",
    "        # poi_list = database_function['getIdbyName'](row.get('poi_id_list', []), poi_cate_dict['attraction'])\n",
    "        # poi_id_list = [i[0] for i in poi_list]\n",
    "        # poi_id_list = list(set(poi_id_list))\n",
    "        # not_poi_id_list = []\n",
    "        # plan_entity = GRASP(\n",
    "        #     N_c_min=row.get('N_c_min', [1, 2, 2]),\n",
    "        #     N_c_max=row.get('N_c_max', [10, 3, 2]),\n",
    "        #     maxIterations=1, \n",
    "        #     poi_id_list=poi_id_list, \n",
    "        #     route_num=row.get('route_num', 3),\n",
    "        #     not_poi_list=not_poi_id_list,\n",
    "        #     use_min_restaurant_gap=row.get('use_min_restaurant_gap', 3) * 3600,\n",
    "        #     start_day_time=row.get('start_day_time', \"09:00:00\"),\n",
    "        #     plan_max_time=row.get('plan_max_time', 12),\n",
    "        #     tightness_w=row.get('tightness_w', 1.0),\n",
    "        #     exp_replace=exp_replace,\n",
    "        #     use_cluster=use_cluster\n",
    "        # )\n",
    "\n",
    "        # Default configurations\n",
    "        default_N_c_min = [1, 2, 2]\n",
    "        default_N_c_max = [10, 3, 2]\n",
    "        default_route_num = 3\n",
    "        default_use_min_restaurant_gap = 3\n",
    "        default_start_day_time = \"09:00:00\"\n",
    "        default_plan_max_time = 12\n",
    "        default_tightness_w = 1.0\n",
    "\n",
    "        # Update database retrieval and type checking\n",
    "        poi_list = database_function['getIdbyName'](row.get('poi_id_list', []), poi_cate_dict['attraction'])\n",
    "        poi_id_list = [i[0] for i in poi_list]\n",
    "        poi_id_list = list(set(poi_id_list))\n",
    "\n",
    "        # Initialize GRASP with safe_get\n",
    "        plan_entity = GRASP(\n",
    "            N_c_min=safe_get(row, 'N_c_min', list, default_N_c_min),\n",
    "            N_c_max=safe_get(row, 'N_c_max', list, default_N_c_max),\n",
    "            maxIterations=1, \n",
    "            poi_id_list=poi_id_list, \n",
    "            route_num=safe_get(row, 'route_num', int, default_route_num),\n",
    "            not_poi_list=[],\n",
    "            use_min_restaurant_gap=safe_get(row, 'use_min_restaurant_gap', int, default_use_min_restaurant_gap) * 3600 if safe_get(row, 'use_min_restaurant_gap', int, default_use_min_restaurant_gap) < 3600 else safe_get(row, 'use_min_restaurant_gap', int, default_use_min_restaurant_gap),\n",
    "            start_day_time=safe_get(row, 'start_day_time', str, default_start_day_time),\n",
    "            plan_max_time=safe_get(row, 'plan_max_time', int, default_plan_max_time),\n",
    "            tightness_w=safe_get(row, 'tightness_w', float, default_tightness_w),\n",
    "            exp_replace=exp_replace,\n",
    "            use_cluster=use_cluster\n",
    "        )\n",
    "\n",
    "        results, st, wt, ts, tt, ds = plan_entity.GRASP()\n",
    "        results_list.append(results)\n",
    "        ts_list.append(ts)\n",
    "\n",
    "    # 计算每个实例的指标\n",
    "    metrics = []\n",
    "    ts_raw = 0\n",
    "    for results in results_list:\n",
    "        results_geos = []\n",
    "        for result in results:\n",
    "            results_geos.append([(poi[poi_dict['poi_long']], poi[poi_dict['poi_lat']]) for poi in result])\n",
    "        # print(results_geos)\n",
    "        # results_geos = np.asarray(results_geos)\n",
    "\n",
    "        instance_metrics = []\n",
    "        overlap_area = max(0, compute_overlap_area(results_geos))\n",
    "        for i, result in enumerate(results_geos):\n",
    "            turning_points, total_distance, repeated_distance = compute_turning_degree(result)\n",
    "            average_turning_angle = compute_average_turning_angle(result)\n",
    "            smoothness = compute_path_smoothness(result)\n",
    "            frechet_distance = 0\n",
    "            if len(results_geos) > 1:\n",
    "                for j in range(len(results_geos)):\n",
    "                    if i != j:\n",
    "                        frechet_distance += compute_frechet_distance(result, results_geos[j])\n",
    "                frechet_distance /= (len(results_geos) - 1)\n",
    "            instance_metrics.append({\n",
    "                \"turning_points\": turning_points,\n",
    "                \"total_distance\": total_distance,\n",
    "                \"repeated_distance\": repeated_distance,\n",
    "                \"average_turning_angle\": average_turning_angle,\n",
    "                \"smoothness\": smoothness,\n",
    "                \"overlap_area\": overlap_area,\n",
    "                \"frechet_distance\": frechet_distance\n",
    "            })\n",
    "        metrics.append(instance_metrics)\n",
    "        \n",
    "        for result in results:\n",
    "            # results_score.append([poi[poi_dict['poi_score']] * math.log2(poi[poi_dict['poi_comment_num']] + 1) for poi in result])\n",
    "            ts_raw += sum([poi[poi_dict['poi_score']] * math.log2(poi[poi_dict['poi_comment_num']] + 1) for poi in result])\n",
    "\n",
    "    # 计算平均值\n",
    "    average_metrics = {\n",
    "        \"turning_points\": 0,\n",
    "        \"total_distance\": 0,\n",
    "        \"repeated_distance\": 0,\n",
    "        \"average_turning_angle\": 0,\n",
    "        \"smoothness\": 0,\n",
    "        \"overlap_area\": 0,\n",
    "        \"frechet_distance\": 0,\n",
    "        \"ts\": 0,\n",
    "        \"ts_raw\": ts_raw\n",
    "    }\n",
    "\n",
    "    num_routes = len(metrics) * len(metrics[0])\n",
    "    for instance_metrics in metrics:\n",
    "        for route_metrics in instance_metrics:\n",
    "            average_metrics[\"turning_points\"] += route_metrics[\"turning_points\"]\n",
    "            average_metrics[\"total_distance\"] += route_metrics[\"total_distance\"]\n",
    "            average_metrics[\"repeated_distance\"] += route_metrics[\"repeated_distance\"]\n",
    "            average_metrics[\"average_turning_angle\"] += route_metrics[\"average_turning_angle\"]\n",
    "            average_metrics[\"smoothness\"] += route_metrics[\"smoothness\"]\n",
    "            average_metrics[\"overlap_area\"] += route_metrics[\"overlap_area\"]\n",
    "            average_metrics[\"frechet_distance\"] += route_metrics[\"frechet_distance\"]\n",
    "    for ts in ts_list:\n",
    "        for s in ts:\n",
    "            average_metrics[\"ts\"] += s\n",
    "\n",
    "    for key in average_metrics:\n",
    "        average_metrics[key] /= num_routes\n",
    "        \n",
    "    database.close()\n",
    "\n",
    "    return average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T05:04:03.917459800Z",
     "start_time": "2024-08-16T05:04:03.904459400Z"
    }
   },
   "outputs": [],
   "source": [
    "# 取消输出warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:\n",
      "Turning points: 4.27\n",
      "Total distance: 0.24\n",
      "repeated_distance: 0.0355\n",
      "Average turning angle: 2.02\n",
      "Smoothness: 11.35\n",
      "Overlap area: 0.0\n",
      "Fréchet distance: 0.10\n",
      "Total score: 133.74880170266266\n",
      "Total score raw: 232.34818925575595\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_name = \"../data/6-final_data_glm4air.json\"\n",
    "\n",
    "with open(file_name,'r', encoding='UTF-8') as f:\n",
    "     cases_dataset = json.load(f)\n",
    "\n",
    "#取前10个case进行测试\n",
    "cases_dataset = cases_dataset[:10]\n",
    "\n",
    "avg_metrics = run_experiment_cases(cases_dataset, use_cluster=False)\n",
    "print(\"Average metrics:\")\n",
    "print(f\"Turning points: {avg_metrics['turning_points']:.2f}\")\n",
    "print(f\"Total distance: {avg_metrics['total_distance']:.2f}\")\n",
    "print(f\"repeated_distance: {avg_metrics['repeated_distance']:.4f}\")\n",
    "print(f\"Average turning angle: {avg_metrics['average_turning_angle']:.2f}\")\n",
    "print(f\"Smoothness: {avg_metrics['smoothness']:.2f}\")\n",
    "print(f\"Overlap area: {avg_metrics['overlap_area']}\")\n",
    "print(f\"Fréchet distance: {avg_metrics['frechet_distance']:.2f}\")\n",
    "print(f\"Total score: {avg_metrics['ts']}\")\n",
    "print(f\"Total score raw: {avg_metrics['ts_raw']}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2400 [00:00<15:01,  2.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [18:03<00:00,  2.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:\n",
      "Turning points: 3.30\n",
      "Total distance: 0.26\n",
      "repeated_distance: 0.0666\n",
      "Average turning angle: 1.19\n",
      "Smoothness: 8.12\n",
      "Overlap area: 0.00041175455803556515\n",
      "Fréchet distance: 0.06\n",
      "Total score: 114.12452879899587\n",
      "Total score raw: 182.17728623102067\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(file_name,'r', encoding='UTF-8') as f:\n",
    "     cases_dataset = json.load(f)\n",
    "\n",
    "avg_metrics = run_experiment_cases(cases_dataset)\n",
    "print(\"Average metrics:\")\n",
    "print(f\"Turning points: {avg_metrics['turning_points']:.2f}\")\n",
    "print(f\"Total distance: {avg_metrics['total_distance']:.2f}\")\n",
    "print(f\"repeated_distance: {avg_metrics['repeated_distance']:.4f}\")\n",
    "print(f\"Average turning angle: {avg_metrics['average_turning_angle']:.2f}\")\n",
    "print(f\"Smoothness: {avg_metrics['smoothness']:.2f}\")\n",
    "print(f\"Overlap area: {avg_metrics['overlap_area']}\")\n",
    "print(f\"Fréchet distance: {avg_metrics['frechet_distance']:.2f}\")\n",
    "print(f\"Total score: {avg_metrics['ts']}\")\n",
    "print(f\"Total score raw: {avg_metrics['ts_raw']}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-16T05:04:03.920453800Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [15:43<00:00,  2.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:\n",
      "Turning points: 3.05\n",
      "Total distance: 0.33\n",
      "repeated_distance: 0.1112\n",
      "Average turning angle: 1.27\n",
      "Smoothness: 7.67\n",
      "Overlap area: 0.0006977949607395149\n",
      "Fréchet distance: 0.05\n",
      "Total score: 106.11133900454776\n",
      "Total score raw: 167.70727813292638\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(file_name,'r', encoding='UTF-8') as f:\n",
    "     cases_dataset = json.load(f)\n",
    "\n",
    "avg_metrics = run_experiment_cases(cases_dataset, use_cluster=False)\n",
    "print(\"Average metrics:\")\n",
    "print(f\"Turning points: {avg_metrics['turning_points']:.2f}\")\n",
    "print(f\"Total distance: {avg_metrics['total_distance']:.2f}\")\n",
    "print(f\"repeated_distance: {avg_metrics['repeated_distance']:.4f}\")\n",
    "print(f\"Average turning angle: {avg_metrics['average_turning_angle']:.2f}\")\n",
    "print(f\"Smoothness: {avg_metrics['smoothness']:.2f}\")\n",
    "print(f\"Overlap area: {avg_metrics['overlap_area']}\")\n",
    "print(f\"Fréchet distance: {avg_metrics['frechet_distance']:.2f}\")\n",
    "print(f\"Total score: {avg_metrics['ts']}\")\n",
    "print(f\"Total score raw: {avg_metrics['ts_raw']}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [13:09<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:\n",
      "Turning points: 3.13\n",
      "Total distance: 0.29\n",
      "repeated_distance: 0.0768\n",
      "Average turning angle: 1.26\n",
      "Smoothness: 7.86\n",
      "Overlap area: 0.0003401172728348556\n",
      "Fréchet distance: 0.06\n",
      "Total score: 101.54719333554324\n",
      "Total score raw: 164.0059956474892\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(file_name,'r', encoding='UTF-8') as f:\n",
    "     cases_dataset = json.load(f)\n",
    "\n",
    "avg_metrics = run_experiment_cases(cases_dataset, exp_replace=False)\n",
    "print(\"Average metrics:\")\n",
    "print(f\"Turning points: {avg_metrics['turning_points']:.2f}\")\n",
    "print(f\"Total distance: {avg_metrics['total_distance']:.2f}\")\n",
    "print(f\"repeated_distance: {avg_metrics['repeated_distance']:.4f}\")\n",
    "print(f\"Average turning angle: {avg_metrics['average_turning_angle']:.2f}\")\n",
    "print(f\"Smoothness: {avg_metrics['smoothness']:.2f}\")\n",
    "print(f\"Overlap area: {avg_metrics['overlap_area']}\")\n",
    "print(f\"Fréchet distance: {avg_metrics['frechet_distance']:.2f}\")\n",
    "print(f\"Total score: {avg_metrics['ts']}\")\n",
    "print(f\"Total score raw: {avg_metrics['ts_raw']}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_cases_choose_i(case_datasets, exp_replace=True, use_cluster=True, max_iterations=2):\n",
    "    # 运行每个实例并收集结果\n",
    "    results_list = []\n",
    "    ts_list = []\n",
    "    database.connect()\n",
    "    for row in tqdm(case_datasets):\n",
    "        # if len(row['poi_name_list']) == 0:\n",
    "        #     continue\n",
    "        default_N_c_min = [1, 2, 2]\n",
    "        default_N_c_max = [10, 3, 2]\n",
    "        default_route_num = 3\n",
    "        default_use_min_restaurant_gap = 3\n",
    "        default_start_day_time = \"09:00:00\"\n",
    "        default_plan_max_time = 12\n",
    "        default_tightness_w = 1.0\n",
    "\n",
    "        # Update database retrieval and type checking\n",
    "        poi_list = database_function['getIdbyName'](row.get('poi_id_list', []), poi_cate_dict['attraction'])\n",
    "        poi_id_list = [i[0] for i in poi_list]\n",
    "        poi_id_list = list(set(poi_id_list))\n",
    "\n",
    "        # Initialize GRASP with safe_get\n",
    "        plan_entity = GRASP(\n",
    "            N_c_min=safe_get(row, 'N_c_min', list, default_N_c_min),\n",
    "            N_c_max=safe_get(row, 'N_c_max', list, default_N_c_max),\n",
    "            maxIterations=max_iterations, \n",
    "            poi_id_list=poi_id_list, \n",
    "            route_num=safe_get(row, 'route_num', int, default_route_num),\n",
    "            not_poi_list=[],\n",
    "            use_min_restaurant_gap=safe_get(row, 'use_min_restaurant_gap', int, default_use_min_restaurant_gap) * 3600 if safe_get(row, 'use_min_restaurant_gap', int, default_use_min_restaurant_gap) < 3600 else safe_get(row, 'use_min_restaurant_gap', int, default_use_min_restaurant_gap),\n",
    "            start_day_time=safe_get(row, 'start_day_time', str, default_start_day_time),\n",
    "            plan_max_time=safe_get(row, 'plan_max_time', int, default_plan_max_time),\n",
    "            tightness_w=safe_get(row, 'tightness_w', float, default_tightness_w),\n",
    "            exp_replace=exp_replace,\n",
    "            use_cluster=use_cluster\n",
    "        )\n",
    "        results, st, wt, ts, tt, ds = plan_entity.GRASP()\n",
    "        results_list.append(results)\n",
    "        ts_list.append(ts)\n",
    "\n",
    "    # 计算每个实例的指标\n",
    "    metrics = []\n",
    "    ts_raw = 0\n",
    "    for results in results_list:\n",
    "        results_geos = []\n",
    "        for result in results:\n",
    "            results_geos.append([(poi[poi_dict['poi_long']], poi[poi_dict['poi_lat']]) for poi in result])\n",
    "        # print(results_geos)\n",
    "        # results_geos = np.asarray(results_geos)\n",
    "\n",
    "        instance_metrics = []\n",
    "        overlap_area = max(0, compute_overlap_area(results_geos))\n",
    "        for i, result in enumerate(results_geos):\n",
    "            turning_points, total_distance, repeated_distance = compute_turning_degree(result)\n",
    "            average_turning_angle = compute_average_turning_angle(result)\n",
    "            smoothness = compute_path_smoothness(result)\n",
    "            frechet_distance = 0\n",
    "            if len(results_geos) > 1:\n",
    "                for j in range(len(results_geos)):\n",
    "                    if i != j:\n",
    "                        frechet_distance += compute_frechet_distance(result, results_geos[j])\n",
    "                frechet_distance /= (len(results_geos) - 1)\n",
    "            instance_metrics.append({\n",
    "                \"turning_points\": turning_points,\n",
    "                \"total_distance\": total_distance,\n",
    "                \"repeated_distance\": repeated_distance,\n",
    "                \"average_turning_angle\": average_turning_angle,\n",
    "                \"smoothness\": smoothness,\n",
    "                \"overlap_area\": overlap_area,\n",
    "                \"frechet_distance\": frechet_distance\n",
    "            })\n",
    "        metrics.append(instance_metrics)\n",
    "        \n",
    "        for result in results:\n",
    "            # results_score.append([poi[poi_dict['poi_score']] * math.log2(poi[poi_dict['poi_comment_num']] + 1) for poi in result])\n",
    "            ts_raw += sum([poi[poi_dict['poi_score']] * math.log2(poi[poi_dict['poi_comment_num']] + 1) for poi in result])\n",
    "\n",
    "    # 计算平均值\n",
    "    average_metrics = {\n",
    "        \"turning_points\": 0,\n",
    "        \"total_distance\": 0,\n",
    "        \"repeated_distance\": 0,\n",
    "        \"average_turning_angle\": 0,\n",
    "        \"smoothness\": 0,\n",
    "        \"overlap_area\": 0,\n",
    "        \"frechet_distance\": 0,\n",
    "        \"ts\": 0,\n",
    "        \"ts_raw\": ts_raw\n",
    "    }\n",
    "\n",
    "    num_routes = len(metrics) * len(metrics[0])\n",
    "    for instance_metrics in metrics:\n",
    "        for route_metrics in instance_metrics:\n",
    "            average_metrics[\"turning_points\"] += route_metrics[\"turning_points\"]\n",
    "            average_metrics[\"total_distance\"] += route_metrics[\"total_distance\"]\n",
    "            average_metrics[\"repeated_distance\"] += route_metrics[\"repeated_distance\"]\n",
    "            average_metrics[\"average_turning_angle\"] += route_metrics[\"average_turning_angle\"]\n",
    "            average_metrics[\"smoothness\"] += route_metrics[\"smoothness\"]\n",
    "            average_metrics[\"overlap_area\"] += route_metrics[\"overlap_area\"]\n",
    "            average_metrics[\"frechet_distance\"] += route_metrics[\"frechet_distance\"]\n",
    "    for ts in ts_list:\n",
    "        for s in ts:\n",
    "            average_metrics[\"ts\"] += s\n",
    "\n",
    "    for key in average_metrics:\n",
    "        average_metrics[key] /= num_routes\n",
    "        \n",
    "    database.close()\n",
    "\n",
    "    return average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [23:22<00:00,  1.71it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:\n",
      "Turning points: 3.18\n",
      "Total distance: 0.29\n",
      "repeated_distance: 0.0753\n",
      "Average turning angle: 1.25\n",
      "Smoothness: 7.93\n",
      "Overlap area: 0.0003208589388774691\n",
      "Fréchet distance: 0.06\n",
      "Total score: 104.20359868011784\n",
      "Total score raw: 168.22779839501572\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(file_name,'r', encoding='UTF-8') as f:\n",
    "     cases_dataset = json.load(f)\n",
    "\n",
    "avg_metrics = run_experiment_cases_choose_i(cases_dataset, exp_replace=False)\n",
    "print(\"Average metrics:\")\n",
    "print(f\"Turning points: {avg_metrics['turning_points']:.2f}\")\n",
    "print(f\"Total distance: {avg_metrics['total_distance']:.2f}\")\n",
    "print(f\"repeated_distance: {avg_metrics['repeated_distance']:.4f}\")\n",
    "print(f\"Average turning angle: {avg_metrics['average_turning_angle']:.2f}\")\n",
    "print(f\"Smoothness: {avg_metrics['smoothness']:.2f}\")\n",
    "print(f\"Overlap area: {avg_metrics['overlap_area']}\")\n",
    "print(f\"Fréchet distance: {avg_metrics['frechet_distance']:.2f}\")\n",
    "print(f\"Total score: {avg_metrics['ts']}\")\n",
    "print(f\"Total score raw: {avg_metrics['ts_raw']}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [33:35<00:00,  1.19it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:\n",
      "Turning points: 3.21\n",
      "Total distance: 0.29\n",
      "repeated_distance: 0.0762\n",
      "Average turning angle: 1.26\n",
      "Smoothness: 8.02\n",
      "Overlap area: 0.00032146308569445215\n",
      "Fréchet distance: 0.06\n",
      "Total score: 105.3658430841116\n",
      "Total score raw: 169.81371953697905\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(file_name,'r', encoding='UTF-8') as f:\n",
    "     cases_dataset = json.load(f)\n",
    "\n",
    "avg_metrics = run_experiment_cases_choose_i(cases_dataset, exp_replace=False, max_iterations=3)\n",
    "print(\"Average metrics:\")\n",
    "print(f\"Turning points: {avg_metrics['turning_points']:.2f}\")\n",
    "print(f\"Total distance: {avg_metrics['total_distance']:.2f}\")\n",
    "print(f\"repeated_distance: {avg_metrics['repeated_distance']:.4f}\")\n",
    "print(f\"Average turning angle: {avg_metrics['average_turning_angle']:.2f}\")\n",
    "print(f\"Smoothness: {avg_metrics['smoothness']:.2f}\")\n",
    "print(f\"Overlap area: {avg_metrics['overlap_area']}\")\n",
    "print(f\"Fréchet distance: {avg_metrics['frechet_distance']:.2f}\")\n",
    "print(f\"Total score: {avg_metrics['ts']}\")\n",
    "print(f\"Total score raw: {avg_metrics['ts_raw']}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [28:29<00:00,  1.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:\n",
      "Turning points: 3.08\n",
      "Total distance: 0.33\n",
      "repeated_distance: 0.1098\n",
      "Average turning angle: 1.26\n",
      "Smoothness: 7.71\n",
      "Overlap area: 0.0006811245920051493\n",
      "Fréchet distance: 0.05\n",
      "Total score: 108.27580124215793\n",
      "Total score raw: 171.0093945980195\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(file_name,'r', encoding='UTF-8') as f:\n",
    "     cases_dataset = json.load(f)\n",
    "\n",
    "avg_metrics = run_experiment_cases_choose_i(cases_dataset, use_cluster=False, max_iterations=2)\n",
    "print(\"Average metrics:\")\n",
    "print(f\"Turning points: {avg_metrics['turning_points']:.2f}\")\n",
    "print(f\"Total distance: {avg_metrics['total_distance']:.2f}\")\n",
    "print(f\"repeated_distance: {avg_metrics['repeated_distance']:.4f}\")\n",
    "print(f\"Average turning angle: {avg_metrics['average_turning_angle']:.2f}\")\n",
    "print(f\"Smoothness: {avg_metrics['smoothness']:.2f}\")\n",
    "print(f\"Overlap area: {avg_metrics['overlap_area']}\")\n",
    "print(f\"Fréchet distance: {avg_metrics['frechet_distance']:.2f}\")\n",
    "print(f\"Total score: {avg_metrics['ts']}\")\n",
    "print(f\"Total score raw: {avg_metrics['ts_raw']}\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
